{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNKrgDnjKtnD8SyfoIP8U+B",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MiguelAngel-ht/Machine_Learning_Models/blob/main/NLP_Intent_Matching_and_Transfer_Learning_.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **CHAT BOT**"
      ],
      "metadata": {
        "id": "O3qknqVO5lAI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## *STEP 1*: INTENT MATCHING\n"
      ],
      "metadata": {
        "id": "Am91TKMYN46C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 2 TYPES TO VECTORIZE A STRING\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.feature_extraction.text import CountVectorizer"
      ],
      "metadata": {
        "id": "0CIECzDybU5N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 2 TYPES TO MEASURE SIMILARITY BETWEEN 2 VECTORS\n",
        "from sklearn.metrics import jaccard_score\n",
        "from sklearn.metrics.pairwise import cosine_similarity"
      ],
      "metadata": {
        "id": "Yc0xO9JjgqzB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# BASIC LIBRARIES TO VECTOR OPERATIONS AND TO GET DATE AND TIME\n",
        "import numpy as np\n",
        "from datetime import datetime"
      ],
      "metadata": {
        "id": "OPC46lYJjiUd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# INITIALIZATION OF VECTORIZERS\n",
        "tfid = TfidfVectorizer()\n",
        "count = CountVectorizer(analyzer='word', ngram_range=(2, 2))"
      ],
      "metadata": {
        "id": "AhPViNaYnZiP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_datetime():\n",
        "  \"\"\" This function is to get current date and time\"\"\"\n",
        "  return str(datetime.now())"
      ],
      "metadata": {
        "id": "J8Eo7HDa40RF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# DEFINITION OF LIST OF QUESTIONS AND ITS RESPECTIVE ANSWERS\n",
        "Questions = ['what is this', 'Who is him', 'What time is it']\n",
        "Answers = ['FAQ BOT CHIDO', 'He is John Wick', get_datetime()]\n",
        "\n",
        "# INPUT TO TEST\n",
        "input = ['what time is']\n",
        "Questions.append(input[0])   # SAVE INPUT IN LAST POSITION"
      ],
      "metadata": {
        "id": "0BpqhFTym_Uf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def Similarity_TFID(Questions):\n",
        "  \"\"\"   Similarity of user's input and questions with vectorizer of TFID  \n",
        "        \n",
        "        atributes: list of strings with Questions       \n",
        "        return: list of values with cosine similarity maching with every Question \n",
        "  \"\"\"\n",
        "  \n",
        "  n = len(Questions)      # GET NUMBER OF QUESTIONS\n",
        "  input_vectorized = tfid.fit_transform(Questions)    # OBJECT OF TFID VECTORIZER\n",
        "  input_vectorized = input_vectorized.toarray()       # CASTING TO AN ARRAY [0.2, 0, 0.4, ...]\n",
        "  best_match_index = []                               # VARIABLE WHEN SIMILARITIES WILL SAVED\n",
        "  \n",
        "  for i in input_vectorized[0:(n-1)]:\n",
        "      \"\"\" Compute Similarity between user's input and all questions registered  \"\"\"\n",
        "      sim = cosine_similarity([i], [input_vectorized[-1]])[0][0]        # COMPUTE COSINE SIMILARITY\n",
        "      best_match_index.append(sim)                                      # SAVE SIMILARITY\n",
        "  \n",
        "  return best_match_index         # RETURN AN ARRAY WITH ALL SIMILARITIES"
      ],
      "metadata": {
        "id": "g0D0rMGDb2FC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def Similarity_Counter(input_vectorized):\n",
        "  \"\"\"   Similarity of user's input and questions with vectorizer of COUNT  \n",
        "        \n",
        "        atributes: list of strings with Questions       \n",
        "        return: list of values with jacard similarity maching with every Question \n",
        "  \"\"\"\n",
        "  \n",
        "  n = len(Questions)          # GET NUMBER OF QUESTIONS\n",
        "  input_vectorized = count.fit_transform(Questions)         # OBJECT OF COUNT VECTORIZER\n",
        "  input_vectorized = input_vectorized.toarray()             # CASTING TO AN ARRAY [1, 0, 1, ...]\n",
        "  best_match_index = []                                     # VARIABLE WHEN SIMILARITIES WILL SAVED\n",
        "\n",
        "  for i in input_vectorized[0:(n-1)]:\n",
        "      \"\"\"Compute Similarity between user's input and all questions registered\"\"\"\n",
        "      sim = jaccard_score(i, input_vectorized[-1])                # COMPUTE JACCARD SIMILARITY\n",
        "      best_match_index.append(sim)                                # SAVE SIMILARITY\n",
        "\n",
        "  return best_match_index       # RETURN AN ARRAY WITH ALL SIMILARITIES"
      ],
      "metadata": {
        "id": "xGMFUMec7wVK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# GET SIMILARITIES AND ADD TO EACH OTHERS\n",
        "best_match_index_a = Similarity_Counter(Questions)\n",
        "best_match_index_b = Similarity_TFID(Questions)\n",
        "best_match_index = np.add(best_match_index_a, best_match_index_b)\n",
        "\n",
        "print('Best Match List: ', best_match_index)\n",
        "\n",
        "# OBTAIN THE MAXIMUM VALUE AND INDEX OF IT\n",
        "t = best_match_index.max()\n",
        "i = np.argmax(best_match_index)\n",
        "\n",
        "# IF T > TO AN UMBRAL 0.5, THE ANSWER IS ENOUGHTLY SIMILAR TO ANSWER\n",
        "if t > 0.5:\n",
        "  print('Answer: ', Answers[t])\n",
        "else:\n",
        "  print(\"\"\"I don't Undertand\"\"\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rEWarVdplFDl",
        "outputId": "234ef9f8-cbe5-4560-c504-72368c603034"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Match List:  [0.4597522  0.15836175 1.41864211]\n",
            "Answer:  2022-11-04 19:52:07.802277\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## *STEP 2*: TEXT CLASSIFICATION"
      ],
      "metadata": {
        "id": "2yHVMKRUE19m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Load Model and Functions\n",
        "\n",
        "# IMPORTING MODEL\n",
        "from tensorflow.keras.models import load_model\n",
        "import pickle\n",
        "import random\n",
        "import nltk\n",
        "# READ DATASET\n",
        "import json\n",
        "from google.colab import output\n",
        "\n",
        "nltk.download('punkt')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('omw-1.4')\n",
        "\n",
        "lemmatizer = nltk.stem.WordNetLemmatizer()\n",
        "\n",
        "words = pickle.load(open('words.pkl','rb'))\n",
        "classes = pickle.load(open('classes.pkl','rb'))\n",
        "model = load_model('chatbot_model.h5')\n",
        "\n",
        "intents = json.loads(open('x.json').read())  # DIRECT DEFITION IN THE SAME CODE\n",
        "\n",
        "def clean_up_Sentence(sentence):\n",
        "  \"\"\" TOKENIZER INPUT DATA TO THE BOT \"\"\"\n",
        "  sentence_words = nltk.word_tokenize(sentence)\n",
        "  sentence_words = [lemmatizer.lemmatize(word) for word in sentence_words]\n",
        "  return sentence_words\n",
        "\n",
        "\n",
        "def bag_of_words(sentence):\n",
        "  \"\"\" BINARIZATION OF INPUT SENTENCE \"\"\"\n",
        "  sentence_words = clean_up_Sentence(sentence)\n",
        "  bag = [0] * len(words)\n",
        "  for w in sentence_words:\n",
        "    for i, word in enumerate(words):\n",
        "      if word == w:\n",
        "        bag[i] = 1\n",
        "  output.clear()\n",
        "  return np.array(bag)\n",
        "\n",
        "\n",
        "def predict_class(sentence):\n",
        "  \"\"\" PREDICTION OF THE MODEL FROM INPUT SENTENCE \"\"\"\n",
        "  bow = bag_of_words(sentence)\n",
        "  res = model.predict(np.array([bow]))[0]\n",
        "  ERROR_TRESHOLD = 0.25\n",
        "  results = [[i,r] for i,r in enumerate(res) if r > ERROR_TRESHOLD]\n",
        "  \n",
        "  results.sort(key=lambda x: x[1], reverse=True)\n",
        "  return_list = []\n",
        "  for r in results:\n",
        "    return_list.append({'intent':classes[r[0]], 'probability': str(r[1])})\n",
        "  return return_list\n",
        "\n",
        "\n",
        "def get_response(intents_list, intents_json):\n",
        "  \"\"\" CHOICE RANDOM RESPONSE OF THE TRAINING RESPONSES DATA \"\"\"\n",
        "  tag = intents_list[0]['intent']\n",
        "  list_of_intents = intents_json['intents']\n",
        "  result = ''\n",
        "  for i in list_of_intents:\n",
        "    if i['tag'] == tag:\n",
        "      result = random.choice(i['responses'])\n",
        "      break\n",
        "  return result\n",
        "\n",
        "output.clear()"
      ],
      "metadata": {
        "cellView": "form",
        "id": "EHqyHPxPLzVV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# LOAD MODEL TO GET GREETING, GOODBYES AND THANKS\n",
        "\n",
        "message = 'dcgkh'                       # INPUT \n",
        "ints = predict_class(message.lower())   # PREDICT CLASS (GREETING, GOODBYE, THANKS OR NOTHING)\n",
        "res = get_response(ints, intents)       # GET RESPONSE\n",
        "print(\"Bot: \",res)                      # PRINT RESPONSE"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8iKGfaTZJAFF",
        "outputId": "2b3e2641-2d8b-419e-fb62-273b13f05dc2"
      },
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Bot:  I don't know what your mean :(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## *STEP 3*: TRANSFER LEARNING"
      ],
      "metadata": {
        "id": "x_iwZ6KaOJDM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# INSTALL LAST VERSION OF OPENAI \n",
        "!pip install --upgrade openai\n",
        "output.clear()"
      ],
      "metadata": {
        "id": "usW-Djg7l4HX"
      },
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# IMPORT OPENAI\n",
        "import openai\n",
        "\n",
        "# API KEY TO USE IT\n",
        "openai.api_key = \"sk- YOUR KEY\""
      ],
      "metadata": {
        "id": "nr-vgBV_OSq7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# INPUT \n",
        "input_ = 'whom is Lionel Messi'\n",
        "\n",
        "# IF THE INPUT DOESN'T ENDS WITH \"?\", THEN IT ADD IT\n",
        "if input[-1] != '?':\n",
        "  input_ += '?'\n",
        "\n",
        "# OPENAI API DAVINCI RECIVE A INPUT AND RETURN A JSON\n",
        "response = openai.Completion.create(\n",
        "  model = \"text-davinci-002\",\n",
        "  prompt = input + \" A:\",\n",
        "  temperature = 0,\n",
        "  max_tokens = 100,\n",
        "  top_p = 1,\n",
        "  frequency_penalty = 0.0,\n",
        "  presence_penalty = 0.0,\n",
        "  stop=[\"\\n\"]\n",
        ")"
      ],
      "metadata": {
        "id": "Rw8qUOHfnsMz"
      },
      "execution_count": 136,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# PRINT RESPONSE OF API\n",
        "print(response['choices'][0]['text'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QVxjIkDwsPsw",
        "outputId": "1e51e998-aae5-49d2-f171-ff53298e179a"
      },
      "execution_count": 137,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Lionel Messi is an Argentine professional footballer who plays as a forward for Spanish club Barcelona and the Argentina national team.\n"
          ]
        }
      ]
    }
  ]
}
